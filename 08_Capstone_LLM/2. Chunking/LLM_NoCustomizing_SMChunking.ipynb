{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce314fc5",
   "metadata": {},
   "source": [
    "# LLM_NoCustomizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1f11562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\piano\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "A Comprehensive Economic Development Strategy (CEDS) is a strategic plan intended to improve the economic well-being and quality of life of a specific region. It is developed through a collaborative process involving various stakeholders, such as businesses, residents, and government entities, and is facilitated by a Comprehensive Economic Development Strategy Committee (Strategy Committee). The Strategy Committee plays a central role in driving the CEDS process, including the development and regular updates of the CEDS document.\n",
      "\n",
      "The CEDS process requires careful consideration of several key steps and components. These include:\n",
      "\n",
      "1. Prioritizing goals and objectives based on available resources, ensuring that the most significant development potential or issues are addressed first. This prioritization is essential for guiding decision-making and establishing a clear vision for the region's economic development.\n",
      "\n",
      "2. Including critical elements in the CEDS document, such as a reasonable estimate of implementation costs, a list of integrated funding sources, and a realistic time frame for execution with relevant benchmarks and performance measures. These components enhance the value of the CEDS, making it both relevant and useful for driving successful implementation.\n",
      "\n",
      "3. Ensuring that the CEDS document is visually appealing and professionally structured, reflecting the organization's or region's capabilities and commitment to effective economic development. This can be achieved by incorporating charts, graphs, and professional photos to emphasize key messages and engage readers.\n",
      "\n",
      "When preparing a CEDS, it is crucial to consider the region's experience with economic development, the complexity of issues, and the level of coordination among stakeholders. The time needed to develop an effective CEDS will depend on these factors, as well as the availability of local resources and organizational capacity.\n",
      "\n",
      "The Economic Development Administration (EDA) can provide valuable guidance and resources for individuals and organizations involved in the CEDS process. Interested parties are encouraged to contact their relevant EDA regional office for more detailed information, including recommended participants and the role of the EDA in supporting CEDS development.\n",
      "\n",
      "In summary, a Comprehensive Economic Development Strategy (CEDS) is a strategic plan that brings together various stakeholders to improve a region's economic well-being and quality of life. By prioritizing goals, incorporating essential elements, and ensuring a professional presentation, the CEDS can serve as an effective guide for resource allocation and the implementation of activities that align with the region's established vision, goals, and objectives. The EDA is a valuable resource for those involved in the CEDS process, offering guidance and support in driving successful economic development strategies.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.docstore.document import Document\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set paths for multiple PDF files\n",
    "pdf_paths = [\"Contents/eda_ceds_guidelines_2023.pdf\"]\n",
    "\n",
    "# Load PDF files\n",
    "documents = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "# --- GPT-3.5 Based Chunking ---\n",
    "def gpt_chunking(documents, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Use GPT-3.5 to semantically chunk the text from documents.\n",
    "    Each chunk is generated based on GPT's understanding of context.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "\n",
    "    for doc in documents:\n",
    "        sentences = sent_tokenize(doc.page_content)\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "\n",
    "        for sentence in sentences:\n",
    "            # Add sentence to the current chunk if it doesn't exceed the chunk size\n",
    "            if current_length + len(sentence) <= chunk_size:\n",
    "                current_chunk.append(sentence)\n",
    "                current_length += len(sentence)\n",
    "            else:\n",
    "                # Process the current chunk with GPT to refine it\n",
    "                refined_chunk = process_with_gpt(\" \".join(current_chunk))\n",
    "                chunks.append(Document(page_content=refined_chunk))\n",
    "                \n",
    "                # Start a new chunk\n",
    "                current_chunk = [sentence]\n",
    "                current_length = len(sentence)\n",
    "\n",
    "        # Process the final chunk\n",
    "        if current_chunk:\n",
    "            refined_chunk = process_with_gpt(\" \".join(current_chunk))\n",
    "            chunks.append(Document(page_content=refined_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def process_with_gpt(text):\n",
    "    \"\"\"\n",
    "    Use GPT-3.5 to refine and validate a chunk of text.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Given the following text:\\n\\n{text}\\n\\n\"\n",
    "        \"Split this text into a coherent chunk that makes sense contextually. \"\n",
    "        \"Make sure the chunk captures the main idea and is self-contained.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "        chunk = response['choices'][0]['message']['content'].strip()\n",
    "        return chunk\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with GPT: {e}\")\n",
    "        return text  # Fallback to original text if GPT processing fails\n",
    "\n",
    "# Perform GPT-based chunking\n",
    "texts = gpt_chunking(documents)\n",
    "\n",
    "# Initialize embedding model for LangChain\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Initialize the LLM model\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "llm = ChatMistralAI(api_key=api_key)\n",
    "\n",
    "# Create a RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Define the query for summarization\n",
    "query = \"Summarize the CEDS(comprehensive Economic Development Strategy) in about 10000 characters\"\n",
    "summary = qa_chain.run(query)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc039f16",
   "metadata": {},
   "source": [
    "## Cosine Similarity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2216d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Cosine Similarity Based] Hallucination Rate: 55.00%\n",
      "\n",
      "Unsupported Sentences (Cosine):\n",
      "1. The CEDS process requires careful consideration of several key steps and components.\n",
      "   Explanation: Average similarity 0.70 < 0.7\n",
      "2. These include:\n",
      "\n",
      "1.\n",
      "   Explanation: Average similarity 0.36 < 0.7\n",
      "3. Prioritizing goals and objectives based on available resources, ensuring that the most significant development potential or issues are addressed first.\n",
      "   Explanation: Average similarity 0.65 < 0.7\n",
      "4. This prioritization is essential for guiding decision-making and establishing a clear vision for the region's economic development.\n",
      "   Explanation: Average similarity 0.67 < 0.7\n",
      "5. 2.\n",
      "   Explanation: Average similarity 0.22 < 0.7\n",
      "6. Including critical elements in the CEDS document, such as a reasonable estimate of implementation costs, a list of integrated funding sources, and a realistic time frame for execution with relevant benchmarks and performance measures.\n",
      "   Explanation: Average similarity 0.61 < 0.7\n",
      "7. These components enhance the value of the CEDS, making it both relevant and useful for driving successful implementation.\n",
      "   Explanation: Average similarity 0.65 < 0.7\n",
      "8. 3.\n",
      "   Explanation: Average similarity 0.21 < 0.7\n",
      "9. This can be achieved by incorporating charts, graphs, and professional photos to emphasize key messages and engage readers.\n",
      "   Explanation: Average similarity 0.44 < 0.7\n",
      "10. The time needed to develop an effective CEDS will depend on these factors, as well as the availability of local resources and organizational capacity.\n",
      "   Explanation: Average similarity 0.58 < 0.7\n",
      "11. Interested parties are encouraged to contact their relevant EDA regional office for more detailed information, including recommended participants and the role of the EDA in supporting CEDS development.\n",
      "   Explanation: Average similarity 0.65 < 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def detect_hallucinations_with_cosine(summary, retriever, embeddings, max_docs=3, similarity_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Measure hallucination rate by comparing each sentence in the summary\n",
    "    with the top retrieved documents using cosine similarity on embeddings.\n",
    "    If the average similarity to retrieved docs is below a threshold, \n",
    "    the sentence is considered a hallucination.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(summary)\n",
    "    unsupported_sentences = []\n",
    "    supported_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Retrieve top relevant documents\n",
    "        relevant_docs = retriever.get_relevant_documents(sentence)[:max_docs]\n",
    "        \n",
    "        # If no documents retrieved, consider it unsupported\n",
    "        if not relevant_docs:\n",
    "            unsupported_sentences.append((sentence, \"No relevant documents retrieved\"))\n",
    "            continue\n",
    "        \n",
    "        # Embed sentence and documents\n",
    "        sentence_embedding = embeddings.embed_documents([sentence])\n",
    "        doc_embeddings = embeddings.embed_documents([doc.page_content for doc in relevant_docs])\n",
    "        \n",
    "        # Calculate cosine similarities and take the average\n",
    "        sims = [cosine_similarity([sentence_embedding[0]], [de])[0][0] for de in doc_embeddings]\n",
    "        avg_sim = np.mean(sims)\n",
    "        \n",
    "        if avg_sim < similarity_threshold:\n",
    "            unsupported_sentences.append((sentence, f\"Average similarity {avg_sim:.2f} < {similarity_threshold}\"))\n",
    "        else:\n",
    "            supported_sentences.append((sentence, f\"Average similarity {avg_sim:.2f} >= {similarity_threshold}\"))\n",
    "\n",
    "    hallucination_rate = len(unsupported_sentences) / len(sentences) * 100 if sentences else 0\n",
    "    return hallucination_rate, unsupported_sentences, supported_sentences\n",
    "\n",
    "cosine_hallucination_rate, cosine_unsupported, cosine_supported = detect_hallucinations_with_cosine(\n",
    "    summary, retriever, embeddings\n",
    ")\n",
    "\n",
    "print(f\"\\n[Cosine Similarity Based] Hallucination Rate: {cosine_hallucination_rate:.2f}%\")\n",
    "\n",
    "if cosine_unsupported:\n",
    "    print(\"\\nUnsupported Sentences (Cosine):\")\n",
    "    for idx, (sent, explanation) in enumerate(cosine_unsupported, 1):\n",
    "        print(f\"{idx}. {sent}\\n   Explanation: {explanation}\")\n",
    "else:\n",
    "    print(\"\\nAll sentences are supported by the source documents (Cosine).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2327be4",
   "metadata": {},
   "source": [
    "## Rouge Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a3b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ROUGE-Based Evaluation] Hallucination Rate: 100.00%\n",
      "\n",
      "Unsupported Sentences (ROUGE):\n",
      "1. A Comprehensive Economic Development Strategy (CEDS) is a strategic plan intended to improve the economic well-being and quality of life of a specific region.\n",
      "   Explanation: Best ROUGE-L recall 0.15 < 0.2\n",
      "2. It is developed through a collaborative process involving various stakeholders, such as businesses, residents, and government entities, and is facilitated by a Comprehensive Economic Development Strategy Committee (Strategy Committee).\n",
      "   Explanation: Best ROUGE-L recall 0.10 < 0.2\n",
      "3. The Strategy Committee plays a central role in driving the CEDS process, including the development and regular updates of the CEDS document.\n",
      "   Explanation: Best ROUGE-L recall 0.13 < 0.2\n",
      "4. The CEDS process requires careful consideration of several key steps and components.\n",
      "   Explanation: Best ROUGE-L recall 0.05 < 0.2\n",
      "5. These include:\n",
      "\n",
      "1.\n",
      "   Explanation: Best ROUGE-L recall 0.02 < 0.2\n",
      "6. Prioritizing goals and objectives based on available resources, ensuring that the most significant development potential or issues are addressed first.\n",
      "   Explanation: Best ROUGE-L recall 0.09 < 0.2\n",
      "7. This prioritization is essential for guiding decision-making and establishing a clear vision for the region's economic development.\n",
      "   Explanation: Best ROUGE-L recall 0.15 < 0.2\n",
      "8. 2.\n",
      "   Explanation: Best ROUGE-L recall 0.00 < 0.2\n",
      "9. Including critical elements in the CEDS document, such as a reasonable estimate of implementation costs, a list of integrated funding sources, and a realistic time frame for execution with relevant benchmarks and performance measures.\n",
      "   Explanation: Best ROUGE-L recall 0.19 < 0.2\n",
      "10. These components enhance the value of the CEDS, making it both relevant and useful for driving successful implementation.\n",
      "   Explanation: Best ROUGE-L recall 0.08 < 0.2\n",
      "11. 3.\n",
      "   Explanation: Best ROUGE-L recall 0.00 < 0.2\n",
      "12. Ensuring that the CEDS document is visually appealing and professionally structured, reflecting the organization's or region's capabilities and commitment to effective economic development.\n",
      "   Explanation: Best ROUGE-L recall 0.15 < 0.2\n",
      "13. This can be achieved by incorporating charts, graphs, and professional photos to emphasize key messages and engage readers.\n",
      "   Explanation: Best ROUGE-L recall 0.13 < 0.2\n",
      "14. When preparing a CEDS, it is crucial to consider the region's experience with economic development, the complexity of issues, and the level of coordination among stakeholders.\n",
      "   Explanation: Best ROUGE-L recall 0.14 < 0.2\n",
      "15. The time needed to develop an effective CEDS will depend on these factors, as well as the availability of local resources and organizational capacity.\n",
      "   Explanation: Best ROUGE-L recall 0.08 < 0.2\n",
      "16. The Economic Development Administration (EDA) can provide valuable guidance and resources for individuals and organizations involved in the CEDS process.\n",
      "   Explanation: Best ROUGE-L recall 0.10 < 0.2\n",
      "17. Interested parties are encouraged to contact their relevant EDA regional office for more detailed information, including recommended participants and the role of the EDA in supporting CEDS development.\n",
      "   Explanation: Best ROUGE-L recall 0.11 < 0.2\n",
      "18. In summary, a Comprehensive Economic Development Strategy (CEDS) is a strategic plan that brings together various stakeholders to improve a region's economic well-being and quality of life.\n",
      "   Explanation: Best ROUGE-L recall 0.15 < 0.2\n",
      "19. By prioritizing goals, incorporating essential elements, and ensuring a professional presentation, the CEDS can serve as an effective guide for resource allocation and the implementation of activities that align with the region's established vision, goals, and objectives.\n",
      "   Explanation: Best ROUGE-L recall 0.11 < 0.2\n",
      "20. The EDA is a valuable resource for those involved in the CEDS process, offering guidance and support in driving successful economic development strategies.\n",
      "   Explanation: Best ROUGE-L recall 0.08 < 0.2\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def detect_hallucinations_with_rouge(summary, retriever, max_docs=3, rouge_threshold=0.2):\n",
    "    \"\"\"\n",
    "    Measure hallucination rate by comparing each sentence in the summary\n",
    "    with retrieved documents using ROUGE-L scores. If the best ROUGE-L recall score\n",
    "    against the retrieved docs is below a certain threshold, consider it a hallucination.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(summary)\n",
    "    unsupported_sentences = []\n",
    "    supported_sentences = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        relevant_docs = retriever.get_relevant_documents(sentence)[:max_docs]\n",
    "\n",
    "        if not relevant_docs:\n",
    "            unsupported_sentences.append((sentence, \"No relevant documents retrieved\"))\n",
    "            continue\n",
    "\n",
    "        # Calculate ROUGE-L scores against each retrieved doc, take the best\n",
    "        rouge_scores = []\n",
    "        for doc in relevant_docs:\n",
    "            scores = scorer.score(doc.page_content, sentence)\n",
    "            rouge_scores.append(scores['rougeL'].recall)\n",
    "\n",
    "        best_rouge_l = max(rouge_scores) if rouge_scores else 0.0\n",
    "\n",
    "        if best_rouge_l < rouge_threshold:\n",
    "            unsupported_sentences.append((sentence, f\"Best ROUGE-L recall {best_rouge_l:.2f} < {rouge_threshold}\"))\n",
    "        else:\n",
    "            supported_sentences.append((sentence, f\"Best ROUGE-L recall {best_rouge_l:.2f} >= {rouge_threshold}\"))\n",
    "\n",
    "    hallucination_rate = len(unsupported_sentences) / len(sentences) * 100 if sentences else 0\n",
    "    return hallucination_rate, unsupported_sentences, supported_sentences\n",
    "\n",
    "rouge_hallucination_rate, rouge_unsupported, rouge_supported = detect_hallucinations_with_rouge(\n",
    "    summary, retriever\n",
    ")\n",
    "\n",
    "print(f\"\\n[ROUGE-Based Evaluation] Hallucination Rate: {rouge_hallucination_rate:.2f}%\")\n",
    "\n",
    "if rouge_unsupported:\n",
    "    print(\"\\nUnsupported Sentences (ROUGE):\")\n",
    "    for idx, (sent, explanation) in enumerate(rouge_unsupported, 1):\n",
    "        print(f\"{idx}. {sent}\\n   Explanation: {explanation}\")\n",
    "else:\n",
    "    print(\"\\nAll sentences are supported by the source documents (ROUGE).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931124a7",
   "metadata": {},
   "source": [
    "## NLI Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695b4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piano\\anaconda3\\envs\\dviz\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sliding Window + NLI Based] Hallucination Rate: 30.00%\n",
      "\n",
      "Unsupported Sentences (NLI):\n",
      "1. These include:\n",
      "\n",
      "1.\n",
      "   Explanation: No entailment found across all windows\n",
      "2. This prioritization is essential for guiding decision-making and establishing a clear vision for the region's economic development.\n",
      "   Explanation: No entailment found across all windows\n",
      "3. 2.\n",
      "   Explanation: No entailment found across all windows\n",
      "4. These components enhance the value of the CEDS, making it both relevant and useful for driving successful implementation.\n",
      "   Explanation: No entailment found across all windows\n",
      "5. 3.\n",
      "   Explanation: No entailment found across all windows\n",
      "6. The EDA is a valuable resource for those involved in the CEDS process, offering guidance and support in driving successful economic development strategies.\n",
      "   Explanation: No entailment found across all windows\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def detect_hallucinations_with_sliding_nli(summary, retriever, max_docs=3, window_size=300, step_size=150, nli_model=\"facebook/bart-large-mnli\"):\n",
    "    \"\"\"\n",
    "    Measure hallucination by:\n",
    "    1. Splitting retrieved document context into sliding windows.\n",
    "    2. Using an NLI model to check if the summary sentence is entailed by any window.\n",
    "\n",
    "    If no window of the retrieved documents provides 'entailment', \n",
    "    consider the sentence hallucinated.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load NLI model and tokenizer\n",
    "    nli_classifier = pipeline(\"text-classification\", model=nli_model, tokenizer=nli_model, return_all_scores=True)\n",
    "\n",
    "    sentences = sent_tokenize(summary)\n",
    "    unsupported_sentences = []\n",
    "    supported_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Retrieve top relevant documents\n",
    "        relevant_docs = retriever.get_relevant_documents(sentence)[:max_docs]\n",
    "        doc_text = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "        if not doc_text.strip():\n",
    "            unsupported_sentences.append((sentence, \"No relevant context retrieved\"))\n",
    "            continue\n",
    "\n",
    "        # Sliding window over the doc_text\n",
    "        # Note: window_size and step_size are character-based splits here for simplicity\n",
    "        # You can adapt to token-based splits if necessary.\n",
    "        doc_length = len(doc_text)\n",
    "        entailment_found = False\n",
    "\n",
    "        for start_idx in range(0, doc_length, step_size):\n",
    "            end_idx = start_idx + window_size\n",
    "            window_text = doc_text[start_idx:end_idx]\n",
    "\n",
    "            # For NLI, we use premise = window_text, hypothesis = sentence\n",
    "            # NLI model typically expects inputs in premise-hypothesis form.\n",
    "            results = nli_classifier(f\"{window_text} </s> {sentence}\")\n",
    "\n",
    "            # results looks like: [[{'label': 'ENTAILMENT', 'score': ...}, {'label':'NEUTRAL',...}, ...]]\n",
    "            # Find the entailment score\n",
    "            for r in results[0]:\n",
    "                if r['label'].lower() == 'entailment' and r['score'] > 0.5:\n",
    "                    entailment_found = True\n",
    "                    break\n",
    "\n",
    "            if entailment_found:\n",
    "                break\n",
    "\n",
    "        if entailment_found:\n",
    "            supported_sentences.append((sentence, \"Entailment found in at least one window\"))\n",
    "        else:\n",
    "            unsupported_sentences.append((sentence, \"No entailment found across all windows\"))\n",
    "\n",
    "    hallucination_rate = (len(unsupported_sentences) / len(sentences) * 100) if sentences else 0\n",
    "    return hallucination_rate, unsupported_sentences, supported_sentences\n",
    "\n",
    "nli_hallucination_rate, nli_unsupported, nli_supported = detect_hallucinations_with_sliding_nli(\n",
    "    summary, retriever\n",
    ")\n",
    "\n",
    "print(f\"\\n[Sliding Window + NLI Based] Hallucination Rate: {nli_hallucination_rate:.2f}%\")\n",
    "\n",
    "if nli_unsupported:\n",
    "    print(\"\\nUnsupported Sentences (NLI):\")\n",
    "    for idx, (sent, explanation) in enumerate(nli_unsupported, 1):\n",
    "        print(f\"{idx}. {sent}\\n   Explanation: {explanation}\")\n",
    "else:\n",
    "    print(\"\\nAll sentences are supported by the source documents (NLI).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8fd564",
   "metadata": {},
   "source": [
    "## LLM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc5c4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[GPT-Based Evaluation] Hallucination Rate: 20.00%\n",
      "\n",
      "Unsupported Sentences (GPT):\n",
      "1. These include:\n",
      "\n",
      "1.\n",
      "   Explanation: no, the sentence \"these include: 1.\" is not directly supported by the provided context. the context discusses the preparation process, alternative plans, and relevant information related to a specific format, but it does not explicitly mention a list of items or numbers such as \"1.\" in the text.\n",
      "2. 2.\n",
      "   Explanation: no, the sentence \"2.\" is not directly supported by the provided context. the context mainly discusses broadband infrastructure and its impact on various aspects, but it does not mention any specific information related to sentence \"2.\".\n",
      "3. These components enhance the value of the CEDS, making it both relevant and useful for driving successful implementation.\n",
      "   Explanation: no, the sentence \"these components enhance the value of the ceds, making it both relevant and useful for driving successful implementation\" is not directly supported by the provided context. the context emphasizes the importance of evaluating outcomes of ceds plans and eda-funded projects based on factors such as jobs, private investment, and a comprehensive set of performance measures, but it does not specifically mention enhancing the value of ceds for successful implementation.\n",
      "4. 3.\n",
      "   Explanation: no, the sentence \"3.\" does not directly align or correspond with the provided context. the context primarily discusses the importance of broadband infrastructure in supporting economic growth, development, equity, health, education, public safety, energy, and civic life, as well as how local needs intersect with state-level plans for promoting broadband access and digital equity.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def detect_hallucinations_with_gpt_direct(summary, retriever, max_docs=3):\n",
    "    \"\"\"\n",
    "    Use GPT (e.g., GPT-3.5-turbo) to evaluate each sentence.\n",
    "    The prompt directly asks GPT if the sentence is supported by the provided context.\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(summary)\n",
    "    unsupported_sentences = []\n",
    "    supported_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        relevant_docs = retriever.get_relevant_documents(sentence)[:max_docs]\n",
    "        context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "        if not context.strip():\n",
    "            unsupported_sentences.append((sentence, \"No context returned by retriever\"))\n",
    "            continue\n",
    "\n",
    "        prompt = (\n",
    "            f\"Below is a context extracted from source documents:\\n\\n{context}\\n\\n\"\n",
    "            f\"Check if the following sentence is directly supported by the provided context. \"\n",
    "            f\"If yes, answer 'Yes' and provide a brief reasoning. If no, answer 'No' and explain why.\\n\\n\"\n",
    "            f\"Sentence: \\\"{sentence}\\\"\"\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant who verifies factual alignment.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            answer = response['choices'][0]['message']['content'].lower()\n",
    "\n",
    "            if \"yes\" in answer:\n",
    "                supported_sentences.append((sentence, answer))\n",
    "            else:\n",
    "                unsupported_sentences.append((sentence, answer))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying GPT: {e}\")\n",
    "            unsupported_sentences.append((sentence, \"Error: Unable to evaluate with GPT\"))\n",
    "\n",
    "    hallucination_rate = len(unsupported_sentences) / len(sentences) * 100 if sentences else 0\n",
    "    return hallucination_rate, unsupported_sentences, supported_sentences\n",
    "\n",
    "gpt_hallucination_rate, gpt_unsupported, gpt_supported = detect_hallucinations_with_gpt_direct(\n",
    "    summary, retriever\n",
    ")\n",
    "\n",
    "print(f\"\\n[GPT-Based Evaluation] Hallucination Rate: {gpt_hallucination_rate:.2f}%\")\n",
    "\n",
    "if gpt_unsupported:\n",
    "    print(\"\\nUnsupported Sentences (GPT):\")\n",
    "    for idx, (sent, explanation) in enumerate(gpt_unsupported, 1):\n",
    "        print(f\"{idx}. {sent}\\n   Explanation: {explanation}\")\n",
    "else:\n",
    "    print(\"\\nAll sentences are supported by the source documents (GPT).\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

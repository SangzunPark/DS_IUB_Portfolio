{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6842ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import langchain as lc\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import create_react_agent, Tool, AgentExecutor\n",
    "from dotenv import load_dotenv\n",
    "from httpx import HTTPStatusError\n",
    "\n",
    "# Set PDF file paths and load them\n",
    "pdf_paths = [\"Contents/eda_ceds_guidelines_2023.pdf\"]\n",
    "documents = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Initialize LLM model\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "llm = ChatMistralAI(api_key=api_key)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Set up relationship extraction model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Initialize knowledge graph (in dictionary format)\n",
    "knowledge_graph = {}\n",
    "\n",
    "# Entity and relationship extraction function\n",
    "def extract_entities_and_relations(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent['word'], ent['entity_group']) for ent in doc]\n",
    "    \n",
    "    # Relationship extraction example - arbitrarily creating relationships (can be replaced with an actual relationship extraction model)\n",
    "    relations = []\n",
    "    for i in range(len(entities) - 1):\n",
    "        relations.append((entities[i], \"related_to\", entities[i + 1]))\n",
    "\n",
    "    return entities, relations\n",
    "\n",
    "# Function to add entities and relationships to the knowledge graph\n",
    "def add_to_knowledge_graph(entities, relations):\n",
    "    for entity, entity_type in entities:\n",
    "        if entity not in knowledge_graph:\n",
    "            knowledge_graph[entity] = {\"type\": entity_type, \"relations\": []}\n",
    "\n",
    "    for head, relation, tail in relations:\n",
    "        head_entity, head_type = head\n",
    "        tail_entity, tail_type = tail\n",
    "        if head_entity in knowledge_graph:\n",
    "            knowledge_graph[head_entity][\"relations\"].append((relation, tail_entity))\n",
    "\n",
    "# Extract entities and relationships from documents and add them to the knowledge graph\n",
    "for text in texts:\n",
    "    entities, relations = extract_entities_and_relations(text.page_content)\n",
    "    add_to_knowledge_graph(entities, relations)\n",
    "\n",
    "# Knowledge graph query function\n",
    "def query_knowledge_graph(query_text):\n",
    "    results = []\n",
    "    for entity, data in knowledge_graph.items():\n",
    "        if query_text.lower() in entity.lower():\n",
    "            results.append((entity, data[\"type\"], data[\"relations\"]))\n",
    "    return results\n",
    "\n",
    "# Enhance QA responses by referencing information from the knowledge graph\n",
    "def enhanced_qa(query):\n",
    "    graph_data = query_knowledge_graph(query)\n",
    "    graph_context = \" \".join([f\"{entity} ({entity_type}) related to {[rel[1] for rel in relations]}\" \n",
    "                              for entity, entity_type, relations in graph_data])\n",
    "    combined_query = f\"{query} Context from knowledge graph: {graph_context}\"\n",
    "    \n",
    "    # Execute the original qa_chain\n",
    "    return qa_chain.run(combined_query)\n",
    "\n",
    "# Define Tool for Agent configuration\n",
    "def retrieve_document(query):\n",
    "    return enhanced_qa(query)\n",
    "\n",
    "document_retrieval_tool = Tool(\n",
    "    name=\"document_retriever\",\n",
    "    func=retrieve_document,\n",
    "    description=\"Retrieve information from documents using QA with knowledge graph context.\"\n",
    ")\n",
    "\n",
    "# Define Agent Prompt\n",
    "agent_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"tools\", \"agent_scratchpad\"],\n",
    "    template=\"\"\"\n",
    "    You are an assistant with access to both document retrieval and knowledge graph tools.\n",
    "\n",
    "    Use the following tools as needed: {tools}\n",
    "\n",
    "    Format your response in this way:\n",
    "    Thought: Describe your reasoning for using certain tools.\n",
    "    Action: Choose one of [{tool_names}] based on the query and available context.\n",
    "    Action Input: Provide the input for the action tool.\n",
    "    Observation: Record the result of the action.\n",
    "\n",
    "    Complete and concise response:\n",
    "    Thought: {agent_scratchpad}\n",
    "    Query: {query}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Initialize Agent\n",
    "tools = [document_retrieval_tool]\n",
    "\n",
    "agent = create_react_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    prompt=agent_prompt\n",
    ")\n",
    "\n",
    "# Set up AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=5)\n",
    "\n",
    "# Apply delay and retry for invocation\n",
    "def invoke_with_delay(executor, input_data, delay=2):\n",
    "    time.sleep(delay)\n",
    "    return executor.invoke(input_data)\n",
    "\n",
    "# Query function using Agent (with exception handling)\n",
    "def agentic_query(query):\n",
    "    input_data = {\n",
    "        \"query\": query,\n",
    "        \"agent_scratchpad\": \"\",\n",
    "    }\n",
    "    try:\n",
    "        # Handle delay and retries\n",
    "        return invoke_with_delay(agent_executor, input_data)\n",
    "    except HTTPStatusError as e:\n",
    "        if e.response.status_code == 429:\n",
    "            print(\"Rate limit exceeded. Retrying after delay...\")\n",
    "            time.sleep(5)  # Set retry delay\n",
    "            return invoke_with_delay(agent_executor, input_data)\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "# Example query execution\n",
    "query = \"Summarize this document in about 5000 characters\"\n",
    "result = agentic_query(query)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

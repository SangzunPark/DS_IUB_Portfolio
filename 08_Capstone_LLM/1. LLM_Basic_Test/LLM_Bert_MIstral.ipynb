{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81de1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import langchain as lc\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load PDF files\n",
    "pdf_paths = [\"Contents/eda_ceds_guidelines_2023.pdf\"]\n",
    "documents = []\n",
    "for path in pdf_paths:\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents.extend(loader.load())\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize embedding model and create vector store\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Initialize LLM model\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "llm = ChatMistralAI(api_key=api_key)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# Set up relationship extraction model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "\n",
    "# Initialize knowledge graph (in dictionary format)\n",
    "knowledge_graph = {}\n",
    "\n",
    "# Entity and relationship extraction function\n",
    "def extract_entities_and_relations(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent['word'], ent['entity_group']) for ent in doc]\n",
    "    \n",
    "    # Relationship extraction example - arbitrarily creating relationships (can be replaced with an actual relationship extraction model)\n",
    "    relations = []\n",
    "    for i in range(len(entities) - 1):\n",
    "        relations.append((entities[i], \"related_to\", entities[i + 1]))\n",
    "\n",
    "    return entities, relations\n",
    "\n",
    "# Function to add entities and relationships to the knowledge graph\n",
    "def add_to_knowledge_graph(entities, relations):\n",
    "    for entity, entity_type in entities:\n",
    "        if entity not in knowledge_graph:\n",
    "            knowledge_graph[entity] = {\"type\": entity_type, \"relations\": []}\n",
    "\n",
    "    for head, relation, tail in relations:\n",
    "        head_entity, head_type = head\n",
    "        tail_entity, tail_type = tail\n",
    "        if head_entity in knowledge_graph:\n",
    "            knowledge_graph[head_entity][\"relations\"].append((relation, tail_entity))\n",
    "\n",
    "# Extract entities and relationships from documents and add them to the knowledge graph\n",
    "for text in texts:\n",
    "    entities, relations = extract_entities_and_relations(text.page_content)\n",
    "    add_to_knowledge_graph(entities, relations)\n",
    "\n",
    "# Knowledge graph query function\n",
    "def query_knowledge_graph(query_text):\n",
    "    results = []\n",
    "    for entity, data in knowledge_graph.items():\n",
    "        if query_text.lower() in entity.lower():\n",
    "            results.append((entity, data[\"type\"], data[\"relations\"]))\n",
    "    return results\n",
    "\n",
    "# Enhance QA responses by referencing information from the knowledge graph\n",
    "def enhanced_qa(query):\n",
    "    graph_data = query_knowledge_graph(query)\n",
    "    graph_context = \" \".join([f\"{entity} ({entity_type}) related to {[rel[1] for rel in relations]}\" \n",
    "                              for entity, entity_type, relations in graph_data])\n",
    "    combined_query = f\"{query} Context from knowledge graph: {graph_context}\"\n",
    "    \n",
    "    # Execute the original qa_chain\n",
    "    return qa_chain.run(combined_query)\n",
    "\n",
    "# Example query execution\n",
    "query = \"Summarize this document in about 5000 characters\"\n",
    "summary = enhanced_qa(query)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f7a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knowledge_graph)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
